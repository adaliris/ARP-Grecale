{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc66766",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "154944b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a6c41",
   "metadata": {},
   "source": [
    "# 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83859133",
   "metadata": {},
   "source": [
    "## 2.1 Youtube data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51cbc224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of folder names (car brands)\n",
    "folders = [\"Alfa Romeo\", \"Audi Q5\", \"BMW X3\", \"Grecale\", \"mercedes GLC\", \"Porsche Macan\"]\n",
    "\n",
    "list_of_dfs = []\n",
    "\n",
    "# Iterate over each folder and get CSV files\n",
    "for folder in folders:\n",
    "    path = f\"/Users/apple/Desktop/test/{folder}/*.csv\"\n",
    "    all_files = glob.glob(path)\n",
    "    \n",
    "    # Read each file in the current folder\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        \n",
    "        # Add the \"Car brand\" column with the folder's name\n",
    "        df[\"Car brand\"] = folder\n",
    "        \n",
    "        # Append the dataframe to the list_of_dfs\n",
    "        list_of_dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list into one dataframe\n",
    "combined_df = pd.concat(list_of_dfs, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5287c0",
   "metadata": {},
   "source": [
    "## 2.2 Combine all sources result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d7f212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                                            Comment  \\\n",
      "0             0.0  What do you think of the Alfa Romeo Stelvio Qu...   \n",
      "1             1.0  I'm not sure I have ever commented on a video,...   \n",
      "2             2.0  I’ve always done the cup holder test in all my...   \n",
      "3             3.0  I absolutely love the design of the Stelvio an...   \n",
      "4             4.0  I believe the reason behind the column mounted...   \n",
      "...           ...                                                ...   \n",
      "60856         NaN  I suppose we should be grateful that at least ...   \n",
      "60857         NaN  Our first macan was a base on 21s with no Pasm...   \n",
      "60858         NaN  For gen3, on the uk configurator PASM is not c...   \n",
      "60859         NaN  Well that is another reason for avoiding the 2...   \n",
      "60860         NaN  We don’t do too bad. At current exchange rates...   \n",
      "\n",
      "                           Name                  Date    Pos    Neg    Neu  \\\n",
      "0                 \\n @ogfeez\\n   4 years ago (edited)  0.049  0.009  0.942   \n",
      "1      \\n @charlesconnor1737\\n            3 years ago  0.207  0.070  0.723   \n",
      "2             \\n @gllegacy87\\n            3 years ago  0.206  0.000  0.794   \n",
      "3          \\n @driftattack11\\n            4 years ago  0.133  0.136  0.731   \n",
      "4         \\n @Black2005Lotus\\n            4 years ago  0.100  0.082  0.818   \n",
      "...                         ...                   ...    ...    ...    ...   \n",
      "60856            Wing Commander      October 02, 2021    NaN    NaN    NaN   \n",
      "60857                    sd1985      October 02, 2021    NaN    NaN    NaN   \n",
      "60858                      BanZ      October 02, 2021    NaN    NaN    NaN   \n",
      "60859                  Col Lamb      October 02, 2021    NaN    NaN    NaN   \n",
      "60860            mark-yorkshire      October 02, 2021    NaN    NaN    NaN   \n",
      "\n",
      "                    Model column   Source  \n",
      "0      Alfa Romeo Stelvio    NaN  Youtube  \n",
      "1      Alfa Romeo Stelvio    NaN  Youtube  \n",
      "2      Alfa Romeo Stelvio    NaN  Youtube  \n",
      "3      Alfa Romeo Stelvio    NaN  Youtube  \n",
      "4      Alfa Romeo Stelvio    NaN  Youtube  \n",
      "...                   ...    ...      ...  \n",
      "60856       Porsche Macan    NaN   Forums  \n",
      "60857       Porsche Macan    NaN   Forums  \n",
      "60858       Porsche Macan    NaN   Forums  \n",
      "60859       Porsche Macan    NaN   Forums  \n",
      "60860       Porsche Macan    NaN   Forums  \n",
      "\n",
      "[60861 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_youtube = combined_df\n",
    "df_youtube.rename(columns={'id': 'Name', 'Car brand': 'Model', 'date': 'Date'}, inplace=True)\n",
    "\n",
    "# convert \"Alfa Romeo\" to \"Alfa Romeo Stelvio\"\n",
    "df_youtube['Model'] = df_youtube['Model'].replace('Alfa Romeo', 'Alfa Romeo Stelvio')\n",
    "# convert \"Grecale\" to \"Maserati Grecale\"\n",
    "df_youtube['Model'] = df_youtube['Model'].replace('Grecale', 'Maserati Grecale')\n",
    "\n",
    "df_youtube['Source'] = 'Youtube'  # 新增Source欄位，標示來源\n",
    "\n",
    "# 讀取CombinedPistonheads.csv文件，並新增Source欄位\n",
    "df_pistonheads = pd.read_csv('/Users/apple/Desktop/CombinedPistonheads.csv')\n",
    "df_pistonheads['Source'] = 'Pistonheads'\n",
    "\n",
    "# 讀取CombinedForums (3).csv文件，並新增Source欄位\n",
    "df_forums = pd.read_csv('/Users/apple/Desktop/CombinedForums (3).csv')\n",
    "df_forums['Source'] = 'Forums'\n",
    "\n",
    "# 合併數據集\n",
    "combined_df = pd.concat([df_youtube, df_pistonheads, df_forums], ignore_index=True)\n",
    "\n",
    "# 顯示合併後的數據集\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29da429",
   "metadata": {},
   "source": [
    "## 2-3 Generate Sentiment Scores for all sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a832d8bc",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd57dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# Function to get sentiment score\n",
    "def get_sentiment_score(text):\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        return -1  # or any placeholder value for invalid inputs\n",
    "    \n",
    "    tokens = tokenizer.encode(text, add_special_tokens=True)  # Add special tokens for BERT (e.g., [CLS], [SEP])\n",
    "    \n",
    "    # Check token length\n",
    "    if len(tokens) > 512:\n",
    "        return -1  # or any other placeholder value\n",
    "    \n",
    "    # Get sentiment score\n",
    "    with torch.no_grad():  # Added to ensure gradients aren't computed\n",
    "        result = model(torch.tensor([tokens]))  # Converted tokens to tensor and added extra dimension\n",
    "    return int(torch.argmax(result.logits)) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b9d6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already generate 0 times.\n",
      "Already generate 1000 times.\n",
      "Already generate 2000 times.\n",
      "Already generate 3000 times.\n",
      "Already generate 4000 times.\n",
      "Already generate 5000 times.\n",
      "Already generate 6000 times.\n",
      "Already generate 7000 times.\n",
      "Already generate 8000 times.\n",
      "Already generate 9000 times.\n",
      "Already generate 10000 times.\n",
      "Already generate 11000 times.\n",
      "Already generate 12000 times.\n",
      "Already generate 13000 times.\n",
      "Already generate 14000 times.\n",
      "Already generate 15000 times.\n",
      "Already generate 16000 times.\n",
      "Already generate 17000 times.\n",
      "Already generate 18000 times.\n",
      "Already generate 19000 times.\n",
      "Already generate 20000 times.\n",
      "Already generate 21000 times.\n",
      "Already generate 22000 times.\n",
      "Already generate 23000 times.\n",
      "Already generate 24000 times.\n",
      "Already generate 25000 times.\n",
      "Already generate 26000 times.\n",
      "Already generate 27000 times.\n",
      "Already generate 28000 times.\n",
      "Already generate 29000 times.\n",
      "Already generate 30000 times.\n",
      "Already generate 31000 times.\n",
      "Already generate 32000 times.\n",
      "Already generate 33000 times.\n",
      "Already generate 34000 times.\n",
      "Already generate 35000 times.\n",
      "Already generate 36000 times.\n",
      "Already generate 37000 times.\n",
      "Already generate 38000 times.\n",
      "Already generate 39000 times.\n",
      "Already generate 40000 times.\n",
      "Already generate 41000 times.\n",
      "Already generate 42000 times.\n",
      "Already generate 43000 times.\n",
      "Already generate 44000 times.\n",
      "Already generate 45000 times.\n",
      "Already generate 46000 times.\n",
      "Already generate 47000 times.\n",
      "Already generate 48000 times.\n",
      "Already generate 49000 times.\n",
      "Already generate 50000 times.\n",
      "Already generate 51000 times.\n",
      "Already generate 52000 times.\n",
      "Already generate 53000 times.\n",
      "Already generate 54000 times.\n",
      "Already generate 55000 times.\n",
      "Already generate 56000 times.\n",
      "Already generate 57000 times.\n",
      "Already generate 58000 times.\n",
      "Already generate 59000 times.\n",
      "Already generate 60000 times.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV\n",
    "df = combined_df\n",
    "df['sentiment_score'] = ''\n",
    "# Fill NaN with empty string\n",
    "df['Comment'].fillna(\"\", inplace=True)\n",
    "df['Comment'] = df['Comment'].astype(str)\n",
    "\n",
    "# # Assuming 'comment' is the column name for the comments\n",
    "# df['sentiment_score'] = df['Comment'].apply(get_sentiment_score)\n",
    "\n",
    "\n",
    "for idx, i in enumerate(df['Comment']):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"Already generate {idx} times.\")\n",
    "    df['sentiment_score'].iloc[idx] = get_sentiment_score(df['Comment'].iloc[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45810c80",
   "metadata": {},
   "source": [
    "## 2-4 Sentiment Scores Processing & Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "598ef719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of removed rows: 0.29%\n",
      "       Unnamed: 0                                            Comment  \\\n",
      "1             1.0  I'm not sure I have ever commented on a video,...   \n",
      "2             2.0  I’ve always done the cup holder test in all my...   \n",
      "3             3.0  I absolutely love the design of the Stelvio an...   \n",
      "4             4.0  I believe the reason behind the column mounted...   \n",
      "5             5.0  Finally! As a previous 4C Spider and now Giuli...   \n",
      "...           ...                                                ...   \n",
      "60856         NaN  I suppose we should be grateful that at least ...   \n",
      "60857         NaN  Our first macan was a base on 21s with no Pasm...   \n",
      "60858         NaN  For gen3, on the uk configurator PASM is not c...   \n",
      "60859         NaN  Well that is another reason for avoiding the 2...   \n",
      "60860         NaN  We don’t do too bad. At current exchange rates...   \n",
      "\n",
      "                           Name              Date    Pos    Neg    Neu  \\\n",
      "1      \\n @charlesconnor1737\\n        3 years ago  0.207  0.070  0.723   \n",
      "2             \\n @gllegacy87\\n        3 years ago  0.206  0.000  0.794   \n",
      "3          \\n @driftattack11\\n        4 years ago  0.133  0.136  0.731   \n",
      "4         \\n @Black2005Lotus\\n        4 years ago  0.100  0.082  0.818   \n",
      "5          \\n @DrachenBlasen\\n        4 years ago  0.171  0.027  0.802   \n",
      "...                         ...               ...    ...    ...    ...   \n",
      "60856            Wing Commander  October 02, 2021    NaN    NaN    NaN   \n",
      "60857                    sd1985  October 02, 2021    NaN    NaN    NaN   \n",
      "60858                      BanZ  October 02, 2021    NaN    NaN    NaN   \n",
      "60859                  Col Lamb  October 02, 2021    NaN    NaN    NaN   \n",
      "60860            mark-yorkshire  October 02, 2021    NaN    NaN    NaN   \n",
      "\n",
      "                    Model   Source sentiment_score  \n",
      "1      Alfa Romeo Stelvio  Youtube               5  \n",
      "2      Alfa Romeo Stelvio  Youtube               4  \n",
      "3      Alfa Romeo Stelvio  Youtube               2  \n",
      "4      Alfa Romeo Stelvio  Youtube               4  \n",
      "5      Alfa Romeo Stelvio  Youtube               5  \n",
      "...                   ...      ...             ...  \n",
      "60856       Porsche Macan   Forums               5  \n",
      "60857       Porsche Macan   Forums               3  \n",
      "60858       Porsche Macan   Forums               4  \n",
      "60859       Porsche Macan   Forums               1  \n",
      "60860       Porsche Macan   Forums               3  \n",
      "\n",
      "[60683 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. 计算sentiment_score为-1的行数\n",
    "num_rows_with_minus_one = len(df[df['sentiment_score'] == -1])\n",
    "\n",
    "# 2. 去除这些行\n",
    "df = df[df['sentiment_score'] != -1]\n",
    "\n",
    "# 3. 计算被删除行的百分比\n",
    "total_rows = len(df)\n",
    "percentage_removed = (num_rows_with_minus_one / (num_rows_with_minus_one + total_rows)) * 100\n",
    "\n",
    "# 顯示被刪除行的百分比\n",
    "print(f\"Percentage of removed rows: {percentage_removed:.2f}%\")\n",
    "\n",
    "# 4. Check if the column exists and drop it\n",
    "if 'column' in df.columns:\n",
    "    df = df.drop('column', axis=1)\n",
    "\n",
    "## df -> only contain YT with scores\n",
    "print(df)\n",
    "\n",
    "# Save the dataframe back to CSV  \n",
    "df.to_csv('/Users/apple/Desktop/combined_final_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240a147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3345687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
